{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b73b04a0",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "202270565d40487b90232c1db7910016",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No module named 'psycopg2'\n",
      "Traceback (most recent call last):\n",
      "ModuleNotFoundError: No module named 'psycopg2'\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import configparser\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "e23dbd27",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "85296f94e7654a749564c776b825c7ed",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Creates spark session and spark context\n",
    "spark_session = SparkSession.builder.getOrCreate()\n",
    "sc = spark_session.sparkContext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "e9c03dce",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a37134e75839429b9945da1bc7104279",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Package already installed for current Spark context!\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/spark/python/lib/pyspark.zip/pyspark/context.py\", line 1110, in install_pypi_package\n",
      "    raise ValueError(\"Package already installed for current Spark context!\")\n",
      "ValueError: Package already installed for current Spark context!\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Install psycopg for further connection with redshift cluster\n",
    "sc.install_pypi_package(\"psycopg2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af23f776",
   "metadata": {},
   "source": [
    "# Data quality checks\n",
    "Data quality checks includes:\n",
    "- Data schema from s3 bucket\n",
    "- No empty table in Redshift"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "812014d9",
   "metadata": {},
   "source": [
    "## Data schema for fact and dimensional tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "a06964a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5483da5b6aa2421fb8bd7fd66035e290",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "FACT_TABLE_CNPJ = 's3://rf-udct-zen/cnpjs_fact_table_csv/'\n",
    "CITIES_DATA = 's3://rf-udct-zen/dimensions/cities_lat_long.csv'\n",
    "CNAES_DATA = 's3://rf-udct-zen/dimensions/cnaes.csv'\n",
    "\n",
    "tables_path = [FACT_TABLE_CNPJ, CITIES_DATA, CNAES_DATA]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "80dec745",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "48049f6cabee4c91a2191315aa48615a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------\n",
      "root\n",
      " |-- cnpj_basico: integer (nullable = true)\n",
      " |-- cnpj: long (nullable = true)\n",
      " |-- matriz_filial: string (nullable = true)\n",
      " |-- razao_social: string (nullable = true)\n",
      " |-- dt_inicioatividade: timestamp (nullable = true)\n",
      " |-- cod_cnae: integer (nullable = true)\n",
      " |-- cep: integer (nullable = true)\n",
      " |-- cod_municipio: integer (nullable = true)\n",
      " |-- porte: string (nullable = true)\n",
      " |-- phone_contact: string (nullable = true)\n",
      " |-- contact_email: string (nullable = true)\n",
      "\n",
      "--------\n",
      "--------\n",
      "root\n",
      " |-- codigo_ibge: integer (nullable = true)\n",
      " |-- nome: string (nullable = true)\n",
      " |-- latitude: double (nullable = true)\n",
      " |-- longitude: double (nullable = true)\n",
      " |-- capital: integer (nullable = true)\n",
      " |-- codigo_uf: integer (nullable = true)\n",
      " |-- siafi_id: integer (nullable = true)\n",
      " |-- ddd: integer (nullable = true)\n",
      " |-- fuso_horario: string (nullable = true)\n",
      "\n",
      "--------\n",
      "--------\n",
      "root\n",
      " |-- cod_cnae: integer (nullable = true)\n",
      " |-- cnae_descricao: string (nullable = true)\n",
      "\n",
      "--------"
     ]
    }
   ],
   "source": [
    "for path in tables_path:\n",
    "    print('-'*8)\n",
    "    table_df = spark.read.option(\"delimiter\",';')\\\n",
    "                        .option(\"encoding\",'iso-8859-1')\\\n",
    "                        .option('header', 'true')\\\n",
    "                        .option('inferSchema', 'true')\\\n",
    "                        .csv(path)\n",
    "    table_df.printSchema()\n",
    "    print('-'*8)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc26b9c5",
   "metadata": {},
   "source": [
    "As can be seen Pyspark has set cnpj_basico and cnpj as integer, what makes sense because these fields contains only numbers. In our scenario, both of them are strings. In this case, is important to set the correct data type in CREATE TABLE SCHEMA. Considering that CNPJ is a formatted number with 14 digits, we cannot remove zeros in the beginning and end of string, because it would make some CNPJs contain less then 14 digits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "978e2b84",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d6ef594a96ca48f39a20c59a5accf471",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fact_table_df = spark.read.option(\"delimiter\",';')\\\n",
    "                        .option(\"dateFormat\",'yyyy-MM-dd')\\\n",
    "                        .option(\"encoding\",'iso-8859-1')\\\n",
    "                        .option('header', 'true')\\\n",
    "                        .option('inferSchema', 'true')\\\n",
    "                        .csv(FACT_TABLE_CNPJ)\n",
    "dim_table_cnae_df = spark.read.option(\"delimiter\",';')\\\n",
    "                        .option(\"encoding\",'iso-8859-1')\\\n",
    "                        .option('header', 'true')\\\n",
    "                        .csv(CNAES_DATA)\n",
    "dim_table_cities_df = spark.read.option(\"delimiter\",';')\\\n",
    "                        .option('header', 'true')\\\n",
    "                        .csv(CITIES_DATA)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28bb80a9",
   "metadata": {},
   "source": [
    "# Checking the total number of rows between S3 files and Redshift"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "fc3af34a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8a6092d2df5943cca81aab375422021f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import configparser\n",
    "import psycopg2 \n",
    "\n",
    "#AWS CREDENTIALS\n",
    "HOST='<INSERT YOUR HOST>'\n",
    "DB_NAME='<INSERT YOUR DBNAME>'\n",
    "DB_USER='<INSERT YOUR USER>'\n",
    "DB_PASSWORD='<INSERT YOUR PASSWORD>'\n",
    "DB_PORT='<DB PORT>'\n",
    "\n",
    "conn = psycopg2.connect(f\"host={HOST} dbname={DB_NAME} user={DB_USER} password={DB_PASSWORD} port={DB_PORT}\")\n",
    "cur = conn.cursor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "e9d26db1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "de862127ec694338be4b741f35a532cf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Total number of records in amazon S3 fact table\n",
    "number_of_records_s3 = fact_table_df.count()\n",
    "\n",
    "# Total number of records in amazon Redshift fact table\n",
    "cur.execute('SELECT COUNT(*) FROM cnpjs_receita_federal')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "3b465f38",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "17e944e0194b4d4c95d0e46a27924eb9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total number of records on Redshift (Fact Table): 864471\n",
      "total number of records on s3 files (Fact Table): 864471"
     ]
    }
   ],
   "source": [
    "print(f'total number of records on Redshift (Fact Table): {cur.fetchone()[0]}')\n",
    "\n",
    "print(f'total number of records on s3 files (Fact Table): {number_of_records_s3}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2736f4e8",
   "metadata": {},
   "source": [
    "#### Unique key constraint\n",
    "In this model, cnpj column should be unique (each stablishment has an unique CNPJ). Lets check if the total number of rows inside cnpj_receita federal table matches the total distinct number of CNPJs "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "b23356dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f4b1216c09c04680a00c14dc1b41edd5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total unique CNPJs: 864471\n",
      "Total number of table records: 864471"
     ]
    }
   ],
   "source": [
    "# Total number of unique CNPJs in amazon Redshift fact table\n",
    "cur.execute('SELECT COUNT(DISTINCT(cnpj)) FROM cnpj_receita_federal')\n",
    "total_unique_cnpj = cur.fetchone()[0]\n",
    "\n",
    "# Total number of records in amazon Redshift fact table\n",
    "cur.execute('SELECT COUNT(*) FROM cnpj_receita_federal')\n",
    "total_registers = cur.fetchone()[0]\n",
    "\n",
    "\n",
    "print(f'Total unique CNPJs: {total_unique_cnpj}')\n",
    "print(f'Total number of table records: {total_registers}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3aa94426",
   "metadata": {},
   "source": [
    "#### Checking dimension tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "a75aa057",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "54d8d20ada22438f8f12256f9f507654",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total number of records on Redshift (CNAE table): 1359\n",
      "total number of records on s3 files (CNAE Table): 1359"
     ]
    }
   ],
   "source": [
    "# Total number of records in amazon S3 dim table\n",
    "number_of_records_s3 = dim_table_cnae_df.count()\n",
    "\n",
    "# Total number of records in amazon Redshift fact table\n",
    "cur.execute('SELECT COUNT(*) FROM cnaes')\n",
    "\n",
    "print(f'total number of records on Redshift (CNAE table): {cur.fetchone()[0]}')\n",
    "print(f'total number of records on s3 files (CNAE Table): {number_of_records_s3}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "505d5eb7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "631d55bab57a4270855698007c340e4c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total number of records on Redshift (CITIES table): 5570\n",
      "total number of records on s3 files (CITIES Table): 5570"
     ]
    }
   ],
   "source": [
    "# Total number of records in amazon S3 dim table\n",
    "number_of_records_s3 = dim_table_cities_df.count()\n",
    "\n",
    "# Total number of records in amazon Redshift fact table\n",
    "cur.execute('SELECT COUNT(*) FROM cities')\n",
    "\n",
    "print(f'total number of records on Redshift (CITIES table): {cur.fetchone()[0]}')\n",
    "print(f'total number of records on s3 files (CITIES Table): {number_of_records_s3}')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PySpark",
   "language": "",
   "name": "pysparkkernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "python",
    "version": 2
   },
   "mimetype": "text/x-python",
   "name": "pyspark",
   "pygments_lexer": "python2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
